{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "32VqGoUiWIW1"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import wikipedia\n",
    "\n",
    "MAX_NUM_ITERATIONS = 100\n",
    "CONVERGENCE_LIMIT = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "oeiCerULWj4J"
   },
   "outputs": [],
   "source": [
    "class KMeans():\n",
    "    # initialize the KMeans object\n",
    "    def __init__(self, x_train, y_train, num_clusters=3, init_type='choose'):\n",
    "        self.data = x_train\n",
    "        self.targets = y_train\n",
    "        self.num_clusters = num_clusters\n",
    "        self.sample_size = x_train.shape[0]\n",
    "        self.feature_size = x_train.shape[1]\n",
    "\n",
    "        if init_type == 'choose':\n",
    "            self.centers = np.copy(self.data[np.random.choice(self.sample_size, self.num_clusters, replace=(False if self.num_clusters <= self.sample_size else True))])\n",
    "        else:       # init_type == 'random'\n",
    "            self.centers = np.random.uniform(size=(self.num_clusters, self.feature_size))\n",
    "\n",
    "        self.prev_centers = np.copy(self.centers)\n",
    "        self.cluster_labels = np.zeros(self.sample_size, dtype=int)\n",
    "\n",
    "    # function to get the norm of 2 vectorized feature vectors\n",
    "    def diff_norm(self, p, q):\n",
    "        return np.linalg.norm(p - q, ord=2, axis=1)\n",
    "\n",
    "    # function to assign clusters to data points based on minimum norm\n",
    "    def assign_clusters(self):\n",
    "        for i in range(self.sample_size):\n",
    "            norms = self.diff_norm(self.data[i], self.centers)\n",
    "            self.cluster_labels[i] = np.argmin(norms)\n",
    "\n",
    "    # function to update the centers (cluster representatives)\n",
    "    def update_centers(self):\n",
    "        self.prev_centers = np.copy(self.centers)\n",
    "        for curr_cluster in range(self.num_clusters):\n",
    "            curr_group = self.data[self.cluster_labels == curr_cluster]\n",
    "            if len(curr_group) != 0:\n",
    "                self.centers[curr_cluster] = np.mean(curr_group, axis = 0)\n",
    "            else:\n",
    "                self.centers[curr_cluster] = np.zeros(self.feature_size)\n",
    "    \n",
    "    # function to calculate the J_clust value\n",
    "    def calculate_loss(self):\n",
    "        return np.mean(np.square(self.diff_norm(self.data, self.centers[self.cluster_labels])))\n",
    "\n",
    "    # function to train the K-Means algorithm\n",
    "    def train(self, details=True):\n",
    "        for i in range(MAX_NUM_ITERATIONS):\n",
    "            self.assign_clusters()\n",
    "            self.update_centers()\n",
    "            loss = self.calculate_loss()\n",
    "            if details:\n",
    "                print(f\"Iteration {i} Loss: {loss}\")\n",
    "                print(\"---------------------------\")\n",
    "            converged = True\n",
    "            for curr_cluster in range(self.num_clusters):\n",
    "                if np.linalg.norm(self.prev_centers[curr_cluster] - self.centers[curr_cluster], ord=2) > CONVERGENCE_LIMIT:\n",
    "                    converged = False\n",
    "            if converged:\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tBBgO58W8V0"
   },
   "outputs": [],
   "source": [
    "titles = [\n",
    "    'Linear algebra',\n",
    "    'Data Science',\n",
    "    'Artificial intelligence',\n",
    "    'European Central Bank',\n",
    "    'Financial technology',\n",
    "    'International Monetary Fund',\n",
    "    'Basketball',\n",
    "    'Swimming',\n",
    "    'Cricket'\n",
    "]\n",
    "\n",
    "# function to load the decument data\n",
    "def load_data():\n",
    "    articles = [wikipedia.page(title, preload=True).content for title in titles]\n",
    "    vectorizer = TfidfVectorizer(stop_words={'english'})\n",
    "    x_train = vectorizer.fit_transform(articles).toarray()\n",
    "    y_train = np.arange(len(titles))\n",
    "\n",
    "    return (x_train, y_train), vectorizer\n",
    "\n",
    "# main function to perform all required tasks\n",
    "def main():\n",
    "    random.seed(60)\n",
    "    np.random.seed(60)\n",
    "    (x_train, y_train), vectorizer = load_data()\n",
    "    k = [4, 8, 12]\n",
    "    loss = []\n",
    "    for num_clusters in k:\n",
    "        print(\"Number of clusters, k = {}\".format(num_clusters))\n",
    "        kmeans = KMeans(x_train, y_train, num_clusters, 'choose')\n",
    "        kmeans.train(details=False)\n",
    "        loss.append(kmeans.calculate_loss())\n",
    "        clusters = [[] for i in range(num_clusters)]\n",
    "        for i, title in enumerate(titles):\n",
    "            index = kmeans.cluster_labels[i]\n",
    "            clusters[index].append(title)\n",
    "        print(\"Clusters obtained:\")\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            print(\"Cluster {}: {}\".format(i + 1, cluster))\n",
    "        print()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "kmeans_documents.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
